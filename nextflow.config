/*
* This configuration file is main one. This includes the pipeline parameters
* and different config files, one for each profile.
* You can switch among them using the Nextflow parameter -profile <<PROFILENAME>>
*/

// include the pipeline parameters from this file
includeConfig "$projectDir/params.config"

// include the base configuration
includeConfig 'conf/base.config'


process {
    // indicates the default container to be used if not defined within the modules
    // container = 'ferriolcalvet/geneid-fetching:latest'

    withLabel: geneidx {
        container = "emiliorighi/geneidx:latest"
    }

    withLabel: samtools {
        container = "quay.io/biocontainers/samtools:1.15--h1170115_1"
    }

    withLabel: diamond {
        container = "quay.io/biocontainers/diamond:0.9.30--h56fc30b_0"
        cpus   = { check_max( 4     * task.attempt, 'cpus'    ) }
        memory = { check_max( 40.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 8.h   * task.attempt, 'time'    ) }
    }
    // custom container options in case you use docker for mapping the users and avoid docker writing files as root
    containerOptions = { workflow.containerEngine == "docker" ? '-u $(id -u):$(id -g)': null}

    // ***********
    // NOT SURE ABOUT THE IMPACT OF THIS CHANGE
    // personalize shell execution, done for avoiding errors in grep
    // ***********
    shell = ['/bin/bash','-u']



}
/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core/genomeannotator Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// genome_annotator workflow params
params {

    // Input options
    assembly             = null
    min_contig_size      = 5000
    npart_size           = 200000
    // npart_size           = 200000000

    // RepeatMasker options
    rm_db                = "https://www.dfam.org/releases/Dfam_3.5/families/Dfam_curatedonly.h5.gz"
    rm_species           = null
    rm_lib               = null


    // place to store the repeat files
    repeats_data_path    = "$projectDir/data"

    // choose to use RepeatModeler or not
    repeat_modeler       = 0

    //update repeat prot file
    update_repeat_prot_file = 0
    
    // GeneidX parameters
  	output			         = "$projectDir/output"
  	taxid				         = null

  	parameter_path       = "$projectDir/data/Parameter_files.taxid/"

  	maps_param_values    = [
      				              "no_score"		: -0.10
                            ]

  	proteins_lower_lim   = 10000
  	proteins_upper_lim   = 30000

  	general_gene_params  = "$projectDir/data/general_gene_model.param"

  	match_score_min      = 300
  	match_ORF_min        = 100

  	intron_margin        = 40

  	min_intron_size      = 20
  	max_intron_size      = 10000

  	source_uniprot       = 1




    // Boilerplate options
    outdir                     = null
    tracedir                   = "${params.outdir}/pipeline_info"
    publish_dir_mode           = 'copy'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    help                       = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'genomes'
    enable_conda               = false

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '10.GB'
    max_cpus                   = 8
    max_time                   = '240.h'

    // Do not remove it, required by RepeatMasker
    dummy_gff                  = 'assets/empty.gff3'

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'


// this should help in removing the "work" directory after the processes have finished successfully
cleanup = false


profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    conda {
        params.enable_conda    = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
// process.shell = ['/bin/bash', '-euo', 'pipefail']
process.shell = ['/bin/bash', '-u']


manifest {
    name            = 'Masking+GeneidX'
    author          = 'Ferriol Calvet (and masking from nf-core genomeannotator )'
    homePage        = 'https://github.com/nf-core/genomeannotator'
    description     = 'Masking and annotation of eukaryotic genomes'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.10.3'
    version         = '0.1'
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
